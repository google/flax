{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " annotated_mnist_example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c808b1d12f3d4f7c8b1f5ad78fb90fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_25473dba4a554f4a87efd587844eed1c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2f92aaf07e094f6a91aa203a47912528",
              "IPY_MODEL_c871ce48e6c0484b951f0d9bc907ef7b"
            ]
          }
        },
        "25473dba4a554f4a87efd587844eed1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f92aaf07e094f6a91aa203a47912528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4674598dc1f747a0987f7a894ff1b0b5",
            "_dom_classes": [],
            "description": "Dl Completed...",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ab8dbe6b2784b58a4cd6115756eace8"
          }
        },
        "c871ce48e6c0484b951f0d9bc907ef7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d315ecc9ba4647d68e31f53a13ba76b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 4/4 [00:00&lt;00:00,  6.48 file/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6846f7f1de64272915a0fc4f43df210"
          }
        },
        "4674598dc1f747a0987f7a894ff1b0b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ab8dbe6b2784b58a4cd6115756eace8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d315ecc9ba4647d68e31f53a13ba76b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6846f7f1de64272915a0fc4f43df210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGPDLcnX-7WT",
        "colab_type": "code",
        "outputId": "e062296c-98c4-48f6-a3eb-7a951f240e41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "!pip install git+https://github.com/google-research/flax.git@prerelease"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/google-research/flax.git@prerelease\n",
            "  Cloning https://github.com/google-research/flax.git (to revision prerelease) to /tmp/pip-req-build-tk28ygok\n",
            "  Running command git clone -q https://github.com/google-research/flax.git /tmp/pip-req-build-tk28ygok\n",
            "  Running command git checkout -b prerelease --track origin/prerelease\n",
            "  Switched to a new branch 'prerelease'\n",
            "  Branch 'prerelease' set up to track remote branch 'prerelease' from 'origin'.\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from flax==0.0.1a0) (1.17.5)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.6/dist-packages (from flax==0.0.1a0) (0.1.38)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.6/dist-packages (from flax==0.0.1a0) (0.1.58)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from flax==0.0.1a0) (3.1.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from flax==0.0.1a0) (0.7)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.6/dist-packages (from flax==0.0.1a0) (0.5.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from jaxlib->flax==0.0.1a0) (1.4.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from jaxlib->flax==0.0.1a0) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.6/dist-packages (from jax->flax==0.0.1a0) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->flax==0.0.1a0) (2.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->flax==0.0.1a0) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->flax==0.0.1a0) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->flax==0.0.1a0) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py->jaxlib->flax==0.0.1a0) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->flax==0.0.1a0) (45.2.0)\n",
            "Building wheels for collected packages: flax\n",
            "  Building wheel for flax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flax: filename=flax-0.0.1a0-cp36-none-any.whl size=58663 sha256=c51c37e7d4fb6751ae3e690bda124e1be838834c6da127842bdcf94222729653\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8n7vrtus/wheels/9b/83/b6/971d75100ac49feb064f934c1026f7c50e7abb681879a959e2\n",
            "Successfully built flax\n",
            "Installing collected packages: flax\n",
            "Successfully installed flax-0.0.1a0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THSa0ukD-8Xi",
        "colab_type": "text"
      },
      "source": [
        "Annotated full end-to-end MNIST example\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz-N0Lrh-9JI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jax\n",
        "import flax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQQrvtcM_yyd",
        "colab_type": "text"
      },
      "source": [
        "JAX has a re-implemented NumPy that runs on GPU and TPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWc4--kI-_SX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jax.numpy as jnp\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skziIf_-_zhu",
        "colab_type": "text"
      },
      "source": [
        "Flax can use any data loading pipeline. We use TF datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYEnTZNF_z5G",
        "colab_type": "code",
        "outputId": "d55290d2-5305-48c1-b78a-7f8e0c3ea5f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        }
      },
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60FiNcgU_0dh",
        "colab_type": "text"
      },
      "source": [
        "A Flax \"module\" lets you write a normal function, which defines learnable parameters in-line. In this case, we define a simple convolutional neural network.\n",
        "\n",
        "Each call to flax.nn.Conv defines a learnable kernel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M87Jk_T_0qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(flax.nn.Module):\n",
        "  \"\"\"A simple CNN model.\"\"\"\n",
        "\n",
        "  def apply(self, x):\n",
        "    x = flax.nn.Conv(x, features=32, kernel_size=(3, 3))\n",
        "    x = flax.nn.relu(x)\n",
        "    x = flax.nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = flax.nn.Conv(x, features=64, kernel_size=(3, 3))\n",
        "    x = flax.nn.relu(x)\n",
        "    x = flax.nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = x.reshape((x.shape[0], -1))  # flatten\n",
        "    x = flax.nn.Dense(x, features=256)\n",
        "    x = flax.nn.relu(x)\n",
        "    x = flax.nn.Dense(x, features=10)\n",
        "    x = flax.nn.log_softmax(x)\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAmnktBrDA72",
        "colab_type": "text"
      },
      "source": [
        "Util function to create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8tqPbbRDBSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(key):\n",
        "  _, initial_params = CNN.init(key, jnp.zeros((1, 28, 28, 1), jnp.float32))\n",
        "  model = nn.Model(CNN, initial_params)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjsQlwaUDBiq",
        "colab_type": "text"
      },
      "source": [
        "Util function to create optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5BalEb6DBz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_optimizer(model, learning_rate, beta):\n",
        "  optimizer_def = flax.optim.Momentum(learning_rate=learning_rate, beta=beta)\n",
        "  optimizer = optimizer_def.create(model)\n",
        "  return optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl29bMrq_012",
        "colab_type": "text"
      },
      "source": [
        "jax.vmap allows us to define the cross_entropy_loss function as if it acts on a single sample. jax.vmap automatically vectorizes code efficiently to run on entire batches.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSdznnAG_1Ci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@jax.vmap\n",
        "def cross_entropy_loss(logits, label):\n",
        "  return -logits[label]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcSgyYht_1QX",
        "colab_type": "text"
      },
      "source": [
        "Compute loss and accuracy. We use jnp (jax.numpy) which can run on device (GPU or TPU).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6XbW-RV_1gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_metrics(logits, labels):\n",
        "  loss = jnp.mean(cross_entropy_loss(logits, labels))\n",
        "  accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
        "  return {'loss': loss, 'accuracy': accuracy}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfUgpwpP_1vI",
        "colab_type": "text"
      },
      "source": [
        "jax.jit traces the train_step function and compiles into fused device operations that run on GPU or TPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh_5-V_P_18x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@jax.jit\n",
        "def train_step(optimizer, batch):\n",
        "  def loss_fn(model):\n",
        "    logits = model(batch['image'])\n",
        "    loss = jnp.mean(cross_entropy_loss(\n",
        "        logits, batch['label']))\n",
        "    return loss, logits\n",
        "  optimizer, _, _ = optimizer.optimize(loss_fn)\n",
        "  return optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KZ2WiSGAcfb",
        "colab_type": "text"
      },
      "source": [
        "Making model predictions is as simple as calling model(input):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98iPpvGNAZL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@jax.jit\n",
        "def eval(model, eval_ds):\n",
        "  logits = model(eval_ds['image'] / 255.0)\n",
        "  return compute_metrics(logits, eval_ds['label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKIVlj5eAdc2",
        "colab_type": "text"
      },
      "source": [
        "**Main train loop**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V8oNXjEAduw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "  # Load and shuffle MNIST.\n",
        "\n",
        "  train_ds = tfds.load('mnist', split=tfds.Split.TRAIN)\n",
        "  train_ds = train_ds.cache().shuffle(1000).batch(128)\n",
        "  test_ds = tfds.as_numpy(tfds.load(\n",
        "      'mnist', split=tfds.Split.TEST, batch_size=-1))\n",
        "  # Create a new model, running all necessary initializers.\n",
        "  # The parameters are stored as nested dicts on model.params.\n",
        "  model = create_model(\n",
        "      jax.random.PRNGKey(0))\n",
        "  # Define an optimizer. At any particular optimzation step, optimizer.target contains the model. \n",
        "  optimizer = create_optimizer(model,\n",
        "                               learning_rate=0.1, beta=0.9)\n",
        "  # Run an optimization step for each batch of training\n",
        "  for epoch in range(10):\n",
        "    for batch in tfds.as_numpy(train_ds):\n",
        "      batch['image'] = batch['image'] / 255.0\n",
        "      optimizer = train_step(optimizer, batch)\n",
        "    \n",
        "    # Once an epoch, evaluate on the test set.\n",
        "    metrics = eval(optimizer.target, test_ds)\n",
        "\n",
        "    # metrics are only retrieved from device when needed on host (like in this print statement)\n",
        "    print('eval epoch: %d, loss: %.4f, accuracy: %.2f'\n",
        "      % (epoch+1,\n",
        "      metrics['loss'], metrics['accuracy'] * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zln58_ZmAeEc",
        "colab_type": "code",
        "outputId": "5a934bcb-9692-4a1a-d593-569c9b11683f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357,
          "referenced_widgets": [
            "c808b1d12f3d4f7c8b1f5ad78fb90fc6",
            "25473dba4a554f4a87efd587844eed1c",
            "2f92aaf07e094f6a91aa203a47912528",
            "c871ce48e6c0484b951f0d9bc907ef7b",
            "4674598dc1f747a0987f7a894ff1b0b5",
            "7ab8dbe6b2784b58a4cd6115756eace8",
            "d315ecc9ba4647d68e31f53a13ba76b7",
            "f6846f7f1de64272915a0fc4f43df210"
          ]
        }
      },
      "source": [
        "train()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead set\n",
            "data_dir=gs://tfds-data/datasets.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.0 (download: 11.06 MiB, generated: Unknown size, total: 11.06 MiB) to /root/tensorflow_datasets/mnist/3.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c808b1d12f3d4f7c8b1f5ad78fb90fc6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Dl Completed...', max=4, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
            "eval epoch: 1, loss: 0.0640, accuracy: 98.03\n",
            "eval epoch: 2, loss: 0.0613, accuracy: 98.06\n",
            "eval epoch: 3, loss: 0.0375, accuracy: 98.76\n",
            "eval epoch: 4, loss: 0.0382, accuracy: 98.71\n",
            "eval epoch: 5, loss: 0.0360, accuracy: 98.92\n",
            "eval epoch: 6, loss: 0.0365, accuracy: 98.92\n",
            "eval epoch: 7, loss: 0.0313, accuracy: 99.14\n",
            "eval epoch: 8, loss: 0.0355, accuracy: 99.05\n",
            "eval epoch: 9, loss: 0.0448, accuracy: 98.77\n",
            "eval epoch: 10, loss: 0.0298, accuracy: 99.14\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}

