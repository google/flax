{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This guide demonstrates various parts of the transfer learning workflow with Flax. Depending on the task, a pretrained model can be used just as a feature extractor or it can be fine-tuned as part of a larger model.\n",
    "\n",
    "This guide demonstrates how to:\n",
    "\n",
    "* Load a pretrained model from HuggingFace [Transformers](https://huggingface.co/docs/transformers/index) and extract a specific sub-module from that pretrained model.\n",
    "* Create a classifier model.\n",
    "* Transfer the pretrained parameters to the new model structure.\n",
    "* Create an optimizer for training different parts of the model separately with [Optax](https://optax.readthedocs.io/).\n",
    "* Set up the model for training.\n",
    "\n",
    "<details><summary><b>Performance Note</b></summary>\n",
    "\n",
    "Depending on your task, some of the content in this guide may be suboptimal. For example, if you are only going to train a linear classifier on top of a pretrained model, it may be better to just extract the feature embeddings once, which can result in much faster training, and you can use specialized algorithms for linear regression or logistic classification. This guide shows how to do transfer learning with all the model parameters.\n",
    "\n",
    "</details><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Note that the Transformers library doesn't use the latest Flax version.\n",
    "! pip install -q \"transformers[flax]\"\n",
    "# Install/upgrade Flax and JAX. For JAX installation with GPU/TPU support,\n",
    "# visit https://github.com/jax-ml/jax#installation.\n",
    "! pip install -U -q flax jax jaxlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function for model loading\n",
    "\n",
    "To load a pre-trained classifier, for convenience first create a function that returns a [Flax `Module`](https://flax.readthedocs.io/en/latest/guides/flax_fundamentals/flax_basics.html#module-basics) and its pretrained variables.\n",
    "\n",
    "In the code below, the `load_model` function uses HuggingFace's `FlaxCLIPVisionModel` model from the [Transformers](https://huggingface.co/docs/transformers/index) library and extracts a `FlaxCLIPModule` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from IPython.display import clear_output\n",
    "from transformers import FlaxCLIPModel\n",
    "\n",
    "# Note: FlaxCLIPModel is not a Flax Module\n",
    "def load_model():\n",
    "  clip = FlaxCLIPModel.from_pretrained('openai/clip-vit-base-patch32')\n",
    "  clear_output(wait=False) # Clear the loading messages\n",
    "  module = clip.module # Extract the Flax Module\n",
    "  variables = {'params': clip.params} # Extract the parameters\n",
    "  return module, variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `FlaxCLIPVisionModel` itself is not a Flax `Module` which is why we need to do this extra step.\n",
    "\n",
    "### Extracting a submodule\n",
    "\n",
    "Calling `load_model` from the snippet above returns the `FlaxCLIPModule`, which is composed of `text_model` and `vision_model` submodules.\n",
    "\n",
    "An easy way to extract the `vision_model` sub-Module defined inside `.setup()` and its variables is to use [`flax.linen.Module.bind`](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html#flax.linen.Module.bind) on the `clip` Module immediately followed by [`flax.linen.Module.unbind`](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html#flax.linen.Module.unbind) on the `vision_model` sub-Module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.linen as nn\n",
    "\n",
    "clip, clip_variables = load_model()\n",
    "vision_model, vision_model_vars = clip.bind(clip_variables).vision_model.unbind()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a classifier\n",
    "\n",
    "To create a classifier define a new Flax [`Module`](https://flax.readthedocs.io/en/latest/guides/flax_fundamentals/flax_basics.html#module-basics) consisting of a `backbone` (the pretrained vision model) and a `head` (the classifier) submodules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "  num_classes: int\n",
    "  backbone: nn.Module\n",
    "  \n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    x = self.backbone(x).pooler_output\n",
    "    x = nn.Dense(\n",
    "      self.num_classes, name='head', kernel_init=nn.zeros)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct a classifier `model`, the `vision_model` Module is passed as the `backbone` to `Classifier`. Then the model's `params` can be randomly initialized by passing fake data that is used to infer the parameter shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "model = Classifier(num_classes=num_classes, backbone=vision_model)\n",
    "\n",
    "x = jnp.empty((1, 224, 224, 3))\n",
    "variables = model.init(jax.random.key(1), x)\n",
    "params = variables['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfering the parameters\n",
    "Since `params` are currently random, the pretrained parameters from `vision_model_vars` have to be transfered to the `params` structure at the appropriate location (i.e. the `backbone`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['backbone'] = vision_model_vars['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** if the model contains other variable collections such as `batch_stats`, these have to be transfered as well.\n",
    "\n",
    "## Optimization\n",
    "\n",
    "If you need to to train different parts of the model separately, you have three options:\n",
    "\n",
    "1. Use `stop_gradient`.\n",
    "2. Filter the parameters for `jax.grad`.\n",
    "3. Use multiple optimizers for different parameters.\n",
    "\n",
    "For most situations we recommend using multiple optimizers via [Optax](https://optax.readthedocs.io/)'s [`multi_transform`](https://optax.readthedocs.io/en/latest/api.html#optax.multi_transform) as its both efficient and can be easily extended to implement many fine-tunning strategies. \n",
    "\n",
    "### **optax.multi_transform**\n",
    "\n",
    "To use `optax.multi_transform` following must be defined:\n",
    "\n",
    "1. The parameter partitions.\n",
    "2. A mapping between partitions and their optimizer.\n",
    "3. A pytree with the same shape as the parameters but its leaves containing the corresponding partition label.\n",
    "\n",
    "To freeze layers with `optax.multi_transform` for the model above, the following setup can be used:\n",
    "\n",
    "* Define the `trainable` and `frozen` parameter partitions.\n",
    "* For the `trainable` parameters select the Adam (`optax.adam`) optimizer.\n",
    "- For the `frozen` parameters select the `optax.set_to_zero` optimizer. This dummy optimizer zeros-out the gradients so no training is done.\n",
    "- Map parameters to partitions using [`flax.traverse_util.path_aware_map`](https://flax.readthedocs.io/en/latest/api_reference/flax.traverse_util.html#flax.traverse_util.path_aware_map), mark the leaves from the `backbone` as `frozen`, and the rest as `trainable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    backbone: {\n",
       "        embeddings: {\n",
       "            class_embedding: 'frozen',\n",
       "            patch_embedding: {\n",
       "                kernel: 'frozen',\n",
       "            },\n",
       "        },\n",
       "    },\n",
       "    head: {\n",
       "        bias: 'trainable',\n",
       "        kernel: 'trainable',\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flax import traverse_util\n",
    "import optax\n",
    "\n",
    "partition_optimizers = {'trainable': optax.adam(5e-3), 'frozen': optax.set_to_zero()}\n",
    "param_partitions = traverse_util.path_aware_map(\n",
    "  lambda path, v: 'frozen' if 'backbone' in path else 'trainable', params)\n",
    "tx = optax.multi_transform(partition_optimizers, param_partitions)\n",
    "\n",
    "# visualize a subset of the param_partitions structure\n",
    "flat = list(traverse_util.flatten_dict(param_partitions).items())\n",
    "traverse_util.unflatten_dict(dict(flat[:2] + flat[-2:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement [differential learning rates](https://blog.slavv.com/differential-learning-rates-59eff5209a4f), the `optax.set_to_zero` can be replaced with any other optimizer, different optimizers and partitioning schemes can be selected depending on the task. For more information on advanced optimizers, refer to Optax's [Combining Optimizers](https://optax.readthedocs.io/en/latest/api.html#combining-optimizers) documentation.\n",
    "\n",
    "## Creating the `TrainState`\n",
    "\n",
    "Once the module, params, and optimizer are defined, the `TrainState` can be constructed as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training.train_state import TrainState\n",
    "\n",
    "state = TrainState.create(\n",
    "  apply_fn=model.apply,\n",
    "  params=params,\n",
    "  tx=tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d8854",
   "metadata": {},
   "source": [
    "Since the optimizer takes care of the freezing or fine-tunning strategy, the `train_step` requires no additional changes, training can proceed normally."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
